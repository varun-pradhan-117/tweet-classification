{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('pytorch-gpu': conda)"
  },
  "interpreter": {
   "hash": "6394067025e7b58be91336a97fabd7e0edf63c22e0826aa98dafbee925a98393"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "source": [
    "## Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tweets    0\n",
       "labels    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "source": [
    "### Removing words from stopword list to consider certain words in final model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stopword list\n",
    "sw_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not----->True\nNo------>True\nAgainst->True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Not----->{'not' in sw_list}\\nNo------>{'no' in sw_list}\\nAgainst->{'against' in sw_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list.remove('not')\n",
    "sw_list.remove('no')\n",
    "sw_list.remove('against')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not----->False\nNo------>False\nAgainst->False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Not----->{'not' in sw_list}\\nNo------>{'no' in sw_list}\\nAgainst->{'against' in sw_list}\")"
   ]
  },
  {
   "source": [
    "### Functions to clean data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize lemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get nltk tag for lemmatizing a given token\n",
    "def nltk_wn_tag(nltk_tag):\n",
    "  if nltk_tag.startswith('J'):\n",
    "    return wordnet.ADJ\n",
    "  elif nltk_tag.startswith('V'):\n",
    "    return wordnet.VERB\n",
    "  elif nltk_tag.startswith('N'):\n",
    "    return wordnet.NOUN\n",
    "  elif nltk_tag.startswith('R'):\n",
    "    return wordnet.ADV\n",
    "  else:                    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lemmatize a sentence\n",
    "def lemmatize_sentence(sentence):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_wn_tag(x[1])), tagged)\n",
    "    lemmatized_words=[]\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if word not in sw_list:\n",
    "            if tag is None:                        \n",
    "                lemmatized_words.append(word)\n",
    "            else:\n",
    "                lemmatized_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    #remove RT(retweet tag)\n",
    "    tweet=re.sub(r\"RT @\",\"@\",tweet)\n",
    "    #remove pings\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
    "    #remove URLs\n",
    "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
    "    #remove special characters\n",
    "    tweet = re.sub(r\"[^a-zA-Z]\", ' ', tweet)\n",
    "    #convert to lower case\n",
    "    tweet=tweet.lower()\n",
    "    #remove extra white spaces\n",
    "    tweet = re.sub(r\" +\",' ', tweet)\n",
    "    #lemmatization of tweet and removing stopwords\n",
    "    lemmatized_tweet=lemmatize_sentence(tweet)\n",
    "    #remove extra white spaces\n",
    "    tweet = re.sub(r\" +\", ' ', tweet)\n",
    "    return lemmatized_tweet.strip()"
   ]
  },
  {
   "source": [
    "### Clean text data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweets']=[clean_tweets(tweet) for tweet in data['tweets']]"
   ]
  },
  {
   "source": [
    "### Removing strings left empty after cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tweets    7\n",
       "labels    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data.eq('').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tweets    0\n",
       "labels    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "data.replace(\"\",np.nan,inplace=True)\n",
    "data.dropna(subset=['tweets'],inplace=True)\n",
    "data.eq('').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1357"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "source": [
    "### Train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=data['tweets']\n",
    "y=data['labels']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=pd.DataFrame(len(tweet.split(' ')) for tweet in X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length=pd.DataFrame(len(tweet.split(' ')) for tweet in X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max(len(tweet.split(' ')) for tweet in X_train)"
   ]
  },
  {
   "source": [
    "### TF-IDF Vectorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf_vect.fit_transform(X_train).toarray()\n",
    "X_test_tfidf=tfidf_vect.transform(X_test).toarray()\n",
    "X_train_tfidf=pd.DataFrame(X_train_tfidf)\n",
    "X_test_tfidf=pd.DataFrame(X_test_tfidf)"
   ]
  },
  {
   "source": [
    "### Combined training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 tweets  labels    0    1  \\\n",
       "0     obama admin cry tax increase applaud china low...       0  0.0  0.0   \n",
       "1     barack obama longboard package core truck mm b...       0  0.0  0.0   \n",
       "2     edshow whenever obama tell truth gop boo hoo h...       0  0.0  0.0   \n",
       "3     many foreign leader obama promise post electio...       0  0.0  0.0   \n",
       "4     obama signal us would accept iranian civilian ...       1  0.0  0.0   \n",
       "...                                                 ...     ...  ...  ...   \n",
       "1080  mean saving scotus tell world obama wrong aca ...       0  0.0  0.0   \n",
       "1081                        obama sharpen kansas vision       0  0.0  0.0   \n",
       "1082                  genius man sing else really obama       1  0.0  0.0   \n",
       "1083  mitt romney obama spend much time harvard also...       0  0.0  0.0   \n",
       "1084  en el backstage de los kca harry le pregunto m...       0  0.0  0.0   \n",
       "\n",
       "        2    3    4         5         6    7  ...  2458  2459  2460  2461  \\\n",
       "0     0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.000000  0.254869  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "...   ...  ...  ...       ...       ...  ...  ...   ...   ...   ...   ...   \n",
       "1080  0.0  0.0  0.0  0.335548  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "1081  0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "1082  0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "1083  0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "1084  0.0  0.0  0.0  0.000000  0.000000  0.0  ...   0.0   0.0   0.0   0.0   \n",
       "\n",
       "      2462  2463  2464  2465  2466  2467  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...  \n",
       "1080   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1081   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1082   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1083   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1084   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1085 rows x 2470 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2458</th>\n      <th>2459</th>\n      <th>2460</th>\n      <th>2461</th>\n      <th>2462</th>\n      <th>2463</th>\n      <th>2464</th>\n      <th>2465</th>\n      <th>2466</th>\n      <th>2467</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>obama admin cry tax increase applaud china low...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>barack obama longboard package core truck mm b...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>edshow whenever obama tell truth gop boo hoo h...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>many foreign leader obama promise post electio...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>obama signal us would accept iranian civilian ...</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.254869</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1080</th>\n      <td>mean saving scotus tell world obama wrong aca ...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.335548</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1081</th>\n      <td>obama sharpen kansas vision</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1082</th>\n      <td>genius man sing else really obama</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1083</th>\n      <td>mitt romney obama spend much time harvard also...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1084</th>\n      <td>en el backstage de los kca harry le pregunto m...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1085 rows × 2470 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "train_data=pd.concat((X_train,y_train),axis=1,ignore_index=True)\n",
    "train_data.columns=['tweets','labels']\n",
    "train_data.reset_index(inplace=True,drop=True)\n",
    "train_data=pd.concat((train_data,X_train_tfidf),axis=1)\n",
    "train_data"
   ]
  },
  {
   "source": [
    "### Combine test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                tweets  labels    0    1    2  \\\n",
       "0    harry style describe michelle obama como una m...       0  0.0  0.0  0.0   \n",
       "1    amp si khady president obama get elect nyrell ...       0  0.0  0.0  0.0   \n",
       "2    obama black american really need time whitey f...       0  0.0  0.0  0.0   \n",
       "3    whatsromneyhiding throw baseball like man not ...       0  0.0  0.0  0.0   \n",
       "4    realclearpolitics obama organizational advanta...       2  0.0  0.0  0.0   \n",
       "..                                                 ...     ...  ...  ...  ...   \n",
       "267         romney attack obama barnstorm pennsylvania       0  0.0  0.0  0.0   \n",
       "268  obama thug bully not sure call rush limbaugh bill       0  0.0  0.0  0.0   \n",
       "269  michelle barack obama become like celebrity ta...       0  0.0  0.0  0.0   \n",
       "270  whatsromneyhiding nothing compare mt proof oba...       1  0.0  0.0  0.0   \n",
       "271  examiner editorial obama budget not ryan antit...       0  0.0  0.0  0.0   \n",
       "\n",
       "       3    4    5         6    7  ...  2458  2459  2460  2461  2462  2463  \\\n",
       "0    0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1    0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2    0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3    0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4    0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "..   ...  ...  ...       ...  ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "267  0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "268  0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "269  0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "270  0.0  0.0  0.0  0.310191  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "271  0.0  0.0  0.0  0.000000  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "     2464  2465  2466  2467  \n",
       "0     0.0   0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0   0.0  \n",
       "2     0.0   0.0   0.0   0.0  \n",
       "3     0.0   0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0   0.0  \n",
       "..    ...   ...   ...   ...  \n",
       "267   0.0   0.0   0.0   0.0  \n",
       "268   0.0   0.0   0.0   0.0  \n",
       "269   0.0   0.0   0.0   0.0  \n",
       "270   0.0   0.0   0.0   0.0  \n",
       "271   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[272 rows x 2470 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2458</th>\n      <th>2459</th>\n      <th>2460</th>\n      <th>2461</th>\n      <th>2462</th>\n      <th>2463</th>\n      <th>2464</th>\n      <th>2465</th>\n      <th>2466</th>\n      <th>2467</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>harry style describe michelle obama como una m...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>amp si khady president obama get elect nyrell ...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>obama black american really need time whitey f...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>whatsromneyhiding throw baseball like man not ...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>realclearpolitics obama organizational advanta...</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>romney attack obama barnstorm pennsylvania</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>obama thug bully not sure call rush limbaugh bill</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>michelle barack obama become like celebrity ta...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>whatsromneyhiding nothing compare mt proof oba...</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.310191</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>examiner editorial obama budget not ryan antit...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>272 rows × 2470 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "test_data=pd.concat((X_test,y_test),axis=1,ignore_index=True)\n",
    "test_data.columns=['tweets','labels']\n",
    "test_data.reset_index(inplace=True,drop=True)\n",
    "test_data=pd.concat((test_data,X_test_tfidf),axis=1)\n",
    "test_data"
   ]
  },
  {
   "source": [
    "### Convert dataframes "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor=torch.tensor(X_train_tfidf.values).float()\n",
    "X_test_tensor=torch.tensor(X_test_tfidf.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor=torch.tensor(y_train.values).float()\n",
    "y_test_tensor=torch.tensor(y_test.values).float()"
   ]
  },
  {
   "source": [
    "# Feed Forward Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Define and create model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Get input shape for Feed forward network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2468"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define FFN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(in_features=INPUT_SHAPE,out_features=64)\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.fc2=nn.Linear(in_features=64,out_features=32)\n",
    "        self.out=nn.Linear(in_features=32,out_features=3)\n",
    "    \n",
    "    def forward(self,t):\n",
    "        # Input layer\n",
    "        t=self.fc1(t)\n",
    "        t=F.relu(t)\n",
    "\n",
    "        # Dropout layer\n",
    "        t=self.dropout(t)\n",
    "\n",
    "        # Hidden layer\n",
    "        t=self.fc2(t)\n",
    "        t=F.relu(t)\n",
    "\n",
    "        # Output layer\n",
    "        t=self.out(t)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "source": [
    "import torch.optim as optim"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "  return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "source": [
    "### Create FFN object and define RMSprop optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FFN object\n",
    "network=FFN()\n",
    "# Define optimizer\n",
    "optimizer=optim.RMSprop(network.parameters(),lr=0.02)"
   ]
  },
  {
   "source": [
    "## Train model for 20 epochs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch =  0 Loss =  1.1387605667114258 Accuracy =  0.25253456221198156\nEpoch =  1 Loss =  1.5284608602523804 Accuracy =  0.6838709677419355\nEpoch =  2 Loss =  5.097789764404297 Accuracy =  0.25253456221198156\nEpoch =  3 Loss =  0.9535832405090332 Accuracy =  0.6838709677419355\nEpoch =  4 Loss =  0.9050535559654236 Accuracy =  0.6866359447004609\nEpoch =  5 Loss =  0.8634213805198669 Accuracy =  0.687557603686636\nEpoch =  6 Loss =  0.820000410079956 Accuracy =  0.6930875576036867\nEpoch =  7 Loss =  0.7771167159080505 Accuracy =  0.6940092165898617\nEpoch =  8 Loss =  0.7115213871002197 Accuracy =  0.6967741935483871\nEpoch =  9 Loss =  0.6041943430900574 Accuracy =  0.7907834101382488\nEpoch =  10 Loss =  0.5318186283111572 Accuracy =  0.8267281105990784\nEpoch =  11 Loss =  0.4325166344642639 Accuracy =  0.8654377880184332\nEpoch =  12 Loss =  0.39344322681427 Accuracy =  0.8866359447004608\nEpoch =  13 Loss =  0.33991849422454834 Accuracy =  0.8903225806451613\nEpoch =  14 Loss =  0.2951522171497345 Accuracy =  0.9069124423963134\nEpoch =  15 Loss =  0.2770167291164398 Accuracy =  0.9142857142857143\nEpoch =  16 Loss =  0.2224370241165161 Accuracy =  0.943778801843318\nEpoch =  17 Loss =  0.22310297191143036 Accuracy =  0.9299539170506912\nEpoch =  18 Loss =  0.17839838564395905 Accuracy =  0.9557603686635945\nEpoch =  19 Loss =  0.20590326189994812 Accuracy =  0.9400921658986175\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    preds=network(X_train_tensor)\n",
    "    loss=F.cross_entropy(preds,y_train_tensor.long())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss=loss.item()\n",
    "    total_correct=get_num_correct(preds,y_train_tensor)\n",
    "    print(\n",
    "        \"Epoch = \",epoch,\n",
    "        \"Loss = \",total_loss,\n",
    "        \"Accuracy = \",total_correct/len(X_train)\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Evaluate model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Set model to eval"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FFN(\n",
       "  (fc1): Linear(in_features=2468, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (out): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "network.eval()"
   ]
  },
  {
   "source": [
    "### Get predictions on test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    final_preds=network(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8088235294117647"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "get_num_correct(final_preds,y_test_tensor)/len(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "len(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_labels=final_preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_tensor,final_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[150,  32,   0],\n",
       "       [ 12,  66,   0],\n",
       "       [  3,   5,   4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "confusion_matrix(y_test_tensor,final_pred_labels)"
   ]
  },
  {
   "source": [
    "# LSTM "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2468"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE=1\n",
    "SEQUENCE_LENGTH=INPUT_SHAPE\n",
    "NUM_LAYERS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2468"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "INPUT_SHAPE"
   ]
  },
  {
   "source": [
    "## Define LSTM NN class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm1=nn.LSTM(INPUT_SHAPE,50,NUM_LAYERS,dropout=0.2,batch_first=True)\n",
    "        \n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.output=nn.Linear(in_features=50,out_features=3)\n",
    "    \n",
    "    def forward(self,t):\n",
    "        # Input layer\n",
    "        # Setting initial cell state to 0\n",
    "        h0=torch.zeros(NUM_LAYERS,t.size(0),50)\n",
    "        c0=torch.zeros(NUM_LAYERS,t.size(0),50)\n",
    "        # Getting LSTM output\n",
    "        out, _ = self.lstm1(t,(h0,c0))\n",
    "\n",
    "        #Only considering final sequence\n",
    "        out=out[:,-1,:]\n",
    "\n",
    "        # Output layer\n",
    "        out=self.output(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "source": [
    "## Reshape input to LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=X_train_tfidf.values.reshape(X_train_tfidf.shape[0],1,X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor=torch.tensor(X_train_tfidf).float()"
   ]
  },
  {
   "source": [
    "## Define optimizer (RMSprop) and train for 20 epochs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch =  1 Loss =  1.1335217952728271 Accuracy =  0.06359447004608294\n",
      "Epoch =  2 Loss =  1.485162615776062 Accuracy =  0.6838709677419355\n",
      "Epoch =  3 Loss =  6.094876766204834 Accuracy =  0.059907834101382486\n",
      "Epoch =  4 Loss =  0.9940123558044434 Accuracy =  0.7889400921658987\n",
      "Epoch =  5 Loss =  0.6427159905433655 Accuracy =  0.7677419354838709\n",
      "Epoch =  6 Loss =  0.45841357111930847 Accuracy =  0.8525345622119815\n",
      "Epoch =  7 Loss =  0.34178319573402405 Accuracy =  0.919815668202765\n",
      "Epoch =  8 Loss =  0.2759753465652466 Accuracy =  0.9235023041474655\n",
      "Epoch =  9 Loss =  0.2301580160856247 Accuracy =  0.9308755760368663\n",
      "Epoch =  10 Loss =  0.19633929431438446 Accuracy =  0.9345622119815669\n",
      "Epoch =  11 Loss =  0.17607669532299042 Accuracy =  0.9345622119815669\n",
      "Epoch =  12 Loss =  0.1581566035747528 Accuracy =  0.9354838709677419\n",
      "Epoch =  13 Loss =  0.1462983638048172 Accuracy =  0.9354838709677419\n",
      "Epoch =  14 Loss =  0.13609574735164642 Accuracy =  0.9345622119815669\n",
      "Epoch =  15 Loss =  0.12233034521341324 Accuracy =  0.9354838709677419\n",
      "Epoch =  16 Loss =  0.1062227189540863 Accuracy =  0.9382488479262673\n",
      "Epoch =  17 Loss =  0.08932467550039291 Accuracy =  0.9622119815668203\n",
      "Epoch =  18 Loss =  0.07014859467744827 Accuracy =  0.992626728110599\n",
      "Epoch =  19 Loss =  0.05097052454948425 Accuracy =  0.9935483870967742\n",
      "Epoch =  20 Loss =  0.036936938762664795 Accuracy =  0.9972350230414746\n"
     ]
    }
   ],
   "source": [
    "# Create FFN object\n",
    "LSTM_net=LSTM()\n",
    "# Define optimizer\n",
    "optimizer2=optim.RMSprop(LSTM_net.parameters(),lr=0.02)\n",
    "for epoch in range(20):\n",
    "    preds=LSTM_net(X_train_tensor)\n",
    "    loss=F.cross_entropy(preds,y_train_tensor.long())\n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "    total_loss=loss.item()\n",
    "    total_correct=get_num_correct(preds,y_train_tensor)\n",
    "    print(\n",
    "        \"Epoch = \",epoch+1,\n",
    "        \"Loss = \",total_loss,\n",
    "        \"Accuracy = \",total_correct/len(X_train)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf=X_test_tfidf.values.reshape(X_test_tfidf.shape[0],1,X_test_tfidf.shape[1])\n",
    "X_test_tensor=torch.tensor(X_test_tfidf).float()"
   ]
  },
  {
   "source": [
    "## Evaluate LSTM model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm1): LSTM(2468, 50, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (output): Linear(in_features=50, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "LSTM_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    LSTM_preds=LSTM_net(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_preds=LSTM_preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8419117647058824\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_tensor,LSTM_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[150,  32,   0],\n",
       "       [ 12,  66,   0],\n",
       "       [  3,   5,   4]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "confusion_matrix(y_test_tensor,final_pred_labels)"
   ]
  }
 ]
}